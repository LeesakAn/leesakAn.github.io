---
title: "Gender Inequality in Language AI Models"
date: ""
description: "Research Assistant (2025 Mar - 2025 Aug)" 
summary: "Research Assistant (2025 Mar - 2025 Aug)" 
cover:
    image: ""
    alt: ""
    relative: true
editPost:
    URL: 
    Text: 
showToc: true
disableAnchoredHeadings: false

---

## Description

As a Research Assistant on the Gender Inequality in Language AI Models project, I help develop evaluation datasets and gender-sensitivity benchmarks. My work includes preparing reference texts, organizing human-coded materials, and supporting the analytical workflow used to assess gender bias in AI-generated language.

## Project Overview

#### Research Focus
+ Analyze how major language models generate gendered descriptions, stereotypes, or unequal representations in political and everyday contexts.
+ Examine whether AI models reflect or distort patterns of gender sensitivity found in real political speech and public communication.
+ Identify structural sources of bias in training corpora by comparing AI-generated text with human-produced datasets.

#### Data and Analytical Framework
+ Utilize gender-sensitivity benchmarks developed from National Assembly transcripts and other political texts.
+ Apply machine-learning dictionaries and human-coded criteria to evaluate AI outputs.
+ Combine linguistic analysis with political discourse frameworks to detect subtle patterns of gendered language.

#### Collaborative Structure
+ Conducted jointly with researchers in political science, linguistics, and computational text analysis
+ Integrates expertise from multiple fields to create more reliable indicators for assessing gender fairness in language models.

